{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://radiant-assets.s3-us-west-2.amazonaws.com/PrimaryRadiantMLHubLogo.png' alt='Radiant MLHub Logo' width='300'/>\n",
    "\n",
    "# How to use the Radiant MLHub API to browse and download a sample dataset\n",
    "\n",
    "This Jupyter notebook, which you may copy and adapt for any use, shows basic examples of how to use the API to download labels and source imagery for the LandCoverNet dataset. Full documentation for the API is available at [docs.mlhub.earth](http://docs.mlhub.earth).\n",
    "\n",
    "We'll show you how to set up your authorization, list collection properties, and retrieve the items (the data contained within them) from those collections.\n",
    "\n",
    "Each item in our collection is explained in json format compliant with STAC label extension definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "This notebook utilizes the [`radiant-mlhub` Python client](https://pypi.org/project/radiant-mlhub/) for interacting with the API. If you are running this notebooks using Binder, then this dependency has already been installed. If you are running this notebook locally, you will need to install this yourself.\n",
    "\n",
    "See the official [`radiant-mlhub` docs](https://radiant-mlhub.readthedocs.io/) for more documentation of the full functionality of that library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "### Create an API Key\n",
    "\n",
    "Access to the Radiant MLHub API requires an API key. To get your API key, go to [dashboard.mlhub.earth](https://dashboard.mlhub.earth). If you have not used Radiant MLHub before, you will need to sign up and create a new account. Otherwise, sign in. In the **API Keys** tab, you'll be able to create API key(s), which you will need. *Do not share* your API key with others: your usage may be limited and sharing your API key is a security risk.\n",
    "\n",
    "### Configure the Client\n",
    "\n",
    "Once you have your API key, you need to configure the `radiant_mlhub` library to use that key. There are a number of ways to configure this (see the [Authentication docs](https://radiant-mlhub.readthedocs.io/en/latest/authentication.html) for details). \n",
    "\n",
    "For these examples, we will set the `MLHUB_API_KEY` environment variable. Run the cell below to save your API key as an environment variable that the client library will recognize.\n",
    "\n",
    "*If you are running this notebook locally and have configured a profile as described in the [Authentication docs](https://radiant-mlhub.readthedocs.io/en/latest/authentication.html), then you do not need to execute this cell.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from radiant_mlhub import Dataset\n",
    "from radiant_mlhub import Collection\n",
    "\n",
    "os.environ['MLHUB_API_KEY'] = 'YOUR API KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all Datasets\n",
    "datasets = Dataset.list()\n",
    "for dataset in datasets:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing Dataset Properties\n",
    "\n",
    "The following cell makes a request to the API for the properties for the NASA Flood Extent Detection Dataset and prints out a few important properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NASA Flood Extent Detection\n",
      "DOI: 10.34911/rdnt.ebk43x\n",
      "Citation: Gahlot, S., Gurung, I., Molthan, A., Maskey, M., & Ramasubramanian, M. (2021) \"Flood Extent Data for Machine Learning\", Version 1.0, Radiant MLHub. [Date Accessed] https://doi.org/10.34911/rdnt.ebk43x\n",
      "\n",
      "Collection IDs and License:\n",
      "    nasa_floods_v1_source : CC-BY-4.0\n",
      "    nasa_floods_v1_labels : CC-BY-4.0\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.fetch('nasa_floods_v1')\n",
    "\n",
    "print(f'Title: {dataset.title}')\n",
    "print(f'DOI: {dataset.doi}')\n",
    "print(f'Citation: {dataset.citation}')\n",
    "print('\\nCollection IDs and License:')\n",
    "for collection in dataset.collections:\n",
    "    print(f'    {collection.id} : {collection.license}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Assets\n",
    "\n",
    "> **NOTE:** If you are running these notebooks using Binder these resources will be downloaded to the remote file system that the notebooks are running on and **not to your local file system.** If you want to download the files to your machine, you will need to clone the repo and run the notebook locally.\n",
    "\n",
    "This next cell will call the dataset download function with a filter specified which only downloads the `raster_label` and `VV` source assets within the `nasa_floods_v1` collection. For more information about filtering downloads, reference the [collection and asset key filtering method in the Python client documenation](https://radiant-mlhub.readthedocs.io/en/latest/datasets.html#filter-by-collection-and-asset-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = {\n",
    "  \"type\": \"Feature\",\n",
    "  \"properties\": {},\n",
    "  \"geometry\": {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "      [\n",
    "        [\n",
    "          88.79150390625,\n",
    "          22.705255477207526\n",
    "        ],\n",
    "        [\n",
    "          93.49365234375,\n",
    "          22.705255477207526\n",
    "        ],\n",
    "        [\n",
    "          93.49365234375,\n",
    "          27.068909095463365\n",
    "        ],\n",
    "        [\n",
    "          88.79150390625,\n",
    "          27.068909095463365\n",
    "        ],\n",
    "        [\n",
    "          88.79150390625,\n",
    "          22.705255477207526\n",
    "        ]\n",
    "      ]\n",
    "    ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "my_start_date=parse(\"2017-06-01T00:00:00+0000\")\n",
    "my_end_date=parse(\"2017-06-30T00:00:00+0000\")\n",
    "\n",
    "asset_filter = dict(\n",
    "    nasa_floods_v1_labels=['raster_label'],\n",
    "    nasa_floods_v1_source=['VV']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.download(intersects=aoi, datetime=(my_start_date, my_end_date), collection_filter=asset_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download All Assets\n",
    "\n",
    "The following cell uses the `dataset.download` function to download the `nasa_floods_v1` dataset to the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
